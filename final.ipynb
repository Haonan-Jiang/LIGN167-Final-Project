{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import tensorflow\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPool1D\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['UserName', 'ScreenName', 'Location', 'TweetAt', 'OriginalTweet',\n",
      "       'Sentiment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# data process\n",
    "# read data\n",
    "train = pd.read_csv('./Corona_NLP_train.csv', encoding='latin-1')\n",
    "test = pd.read_csv('./Corona_NLP_train.csv', encoding='latin-1')\n",
    "print(train.columns)\n",
    "\n",
    "# get rid of irrelevant columns\n",
    "train = train[['OriginalTweet', 'Sentiment']]\n",
    "test = test[['OriginalTweet', 'Sentiment']]\n",
    "\n",
    "# clean the original text by removing urls\n",
    "def remove_url(original_tweet): \n",
    "    url_pattern  = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    return url_pattern.sub(r'', original_tweet)\n",
    "\n",
    "train.dropna()\n",
    "train['OriginalTweet'] = train['OriginalTweet'].apply(remove_url)\n",
    "\n",
    "# convert label to float\n",
    "label_encoder = LabelEncoder()\n",
    "train['Sentiment'] = label_encoder.fit_transform(train['Sentiment'])\n",
    "\n",
    "# tokenize\n",
    "tokenizer = Tokenizer(num_words=20000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train['OriginalTweet'])\n",
    "sequence = tokenizer.texts_to_sequences(train['OriginalTweet'])\n",
    "# pad\n",
    "padded = pad_sequences(sequence, maxlen=50, padding=\"post\")\n",
    "# split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(padded, train['Sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1029/1029 [==============================] - 17s 15ms/step - loss: -7.4726 - accuracy: 0.1145 - val_loss: -8.8904 - val_accuracy: 0.1290\n",
      "Epoch 2/10\n",
      "1029/1029 [==============================] - 15s 15ms/step - loss: -8.9061 - accuracy: 0.1296 - val_loss: -8.8910 - val_accuracy: 0.1288\n",
      "Epoch 3/10\n",
      "1029/1029 [==============================] - 15s 15ms/step - loss: -8.9191 - accuracy: 0.1260 - val_loss: -8.8974 - val_accuracy: 0.1291\n",
      "Epoch 4/10\n",
      "1029/1029 [==============================] - 15s 14ms/step - loss: -8.9330 - accuracy: 0.1254 - val_loss: -8.9019 - val_accuracy: 0.1260\n",
      "Epoch 5/10\n",
      "1029/1029 [==============================] - 15s 14ms/step - loss: -9.7092 - accuracy: 0.1209 - val_loss: -10.5653 - val_accuracy: 0.1194\n",
      "Epoch 6/10\n",
      "1029/1029 [==============================] - 15s 14ms/step - loss: -10.9250 - accuracy: 0.1144 - val_loss: -12.2416 - val_accuracy: 0.1088\n",
      "Epoch 7/10\n",
      "1029/1029 [==============================] - 15s 15ms/step - loss: -14.8535 - accuracy: 0.1050 - val_loss: -17.5203 - val_accuracy: 0.1051\n",
      "Epoch 8/10\n",
      "1029/1029 [==============================] - 15s 15ms/step - loss: -18.7853 - accuracy: 0.0923 - val_loss: -18.9247 - val_accuracy: 0.0967\n",
      "Epoch 9/10\n",
      "1029/1029 [==============================] - 15s 15ms/step - loss: -20.1635 - accuracy: 0.0711 - val_loss: -20.0201 - val_accuracy: 0.0856\n",
      "Epoch 10/10\n",
      "1029/1029 [==============================] - 15s 15ms/step - loss: -20.8239 - accuracy: 0.0566 - val_loss: -19.9995 - val_accuracy: 0.0660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x160e1b4ec40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining model\n",
    "model = tensorflow.keras.Sequential()\n",
    "# adding layers\n",
    "# use common values for most of the hyperparameters, might test and change later...\n",
    "model.add(Embedding(20000, 100, input_length=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu')) \n",
    "model.add(MaxPool1D(pool_size=4))\n",
    "model.add(tensorflow.keras.layers.LSTM(100))\n",
    "Dense(1, activation='sigmoid')\n",
    "# compile and train\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(x_train, y_train, validation_data = (x_valid, y_valid), batch_size = 32, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258/258 [==============================] - 1s 2ms/step\n",
      "[[1.         1.         1.         ... 1.         1.         1.        ]\n",
      " [1.         1.         1.         ... 1.         1.         1.        ]\n",
      " [1.         1.         1.         ... 1.         1.         1.        ]\n",
      " ...\n",
      " [1.         0.9999995  0.9999995  ... 0.99999994 1.         1.        ]\n",
      " [1.         1.         1.         ... 1.         1.         1.        ]\n",
      " [1.         1.         1.         ... 1.         1.         1.        ]]\n",
      "258/258 [==============================] - 1s 2ms/step - loss: -19.9995 - accuracy: 0.0660\n"
     ]
    }
   ],
   "source": [
    "# predict using the validation set\n",
    "y_pred = model.predict(x_valid)\n",
    "print(y_pred)\n",
    "accuracy = model.evaluate(x_valid, y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf07f02b6c14379d2e1909468a97989c0510d3d871c5ba85f902670976dfe967"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
